\documentclass[a4paper,10pt]{scrartcl}

% Inclusión de paquetes
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{verbatim}
\usepackage{amsthm}

% Definiciones
\newtheorem*{mydef}{Definición}
\newtheorem{mydefn}{Definición}
\newtheorem{theorem}{Teorema}
\newtheorem{fact}{Proposición}
\newtheorem{corollary}{Corolario}
\everymath{\displaystyle} % Displaystyle por defecto

% Comandos
\newcommand{\Referencia}[4]{\indent #1, \textbf{#2}. \textit{#3}, \textit{#4}.\\}
\renewcommand\refname{Referencias}
\renewcommand\contentsname{Contenidos}
\numberwithin{equation}{section}
\setlength{\parindent}{0cm} % Sin sangrías
\setlength{\parskip}{0.1cm}

% Sintaxis: \Algoritmo{Elementos de entrada}{Elementos de proceso}{Elementos de salida}
\newcommand{\Algoritmo}[3]{\textbf{Entrada} \begin{itemize} #1 \end{itemize} \textbf{Proceso} \begin{enumerate} #2 \end{enumerate} \textbf{Salida} \begin{itemize} #3 \end{itemize}}

\title{Teoría de Colas}
\author{
  Marta Andrés\and
  Ignacio Cordón\and
  Bartolomé Ortiz\and
}
\date{}


\begin{document}
\maketitle
\tableofcontents
\pagebreak

\section{Introducción}

\subsection{El modelo de un \textit{``sistema de encolado''}}
Un sistema de encolado es una cosa tal que así [dibujo aquí], en la que se consideran las siguientes variables:


\begin{itemize}
\item [$c$]
  Número (fijo) de servidores en el sistema.
\item [$\tau$]
  Variable aleatoria que describe el tiempo entre llegadas (de clientes).
\item [$s$]
  Variable aleatoria que describe el tiempo de servicio.
  %% o [que tarda un cliente en ser servido] ?
\item [$q$]
  Variable aleatoria que describe el tiempo que espera un cliente en la cola.
  %% [incóginta?]
\item [$N_s \lbrack t \rbrack$]
  Variable aleatoria que describe el número de clientes siendo servidos en el instante $t$.
  %% [dependerá de $\tau$, $s$, $c$? y de más cosas?]
\item [$N_q \lbrack t \rbrack$]
  Variable aleatoria que describe el número de clientes en la cola (esperando a ser servidos) en el instante $t$.
  %% [depende también?]
\end{itemize}

%% Resaltar que $q$ no se conoce y es la que interesa conocer en general? $N_q[t]$ y $N_s[t]$ dependen también de otras cosas.

De ellos se derivan las siguientes variables, también relevantes:
\begin{itemize}
\item [$\lambda$]
  Frecuencia esperada de llegadas de clientes al sistema: $\lambda = 1/E[\tau]$.
\item [$\mu$]
  Frecuencia esperada de servicio de los servidores del sistema: $\mu = 1/E[s]$.
\item [$\rho$]
  Aprovechamiento de los servidores, esto es, la proporción de tiempo que los servidores están trabajando: $\rho = \frac{\lambda}{c\mu}$.
  %% $= \frac{E[N_s]}{c} = \frac{L_s}{c}$ por qué?
\item [$W_s$]
  Tiempo esperado que está siendo servido un cliente: $W_s  = E[s]$.
\item [$W_q$]
  Tiempo esperado que está un cliente en la cola: $W_q = E[q]$.
\item [$w$]
  Variable aleatoria que describe el tiempo total que un cliente está en el sistema de encolado: $w = q+s$.
\item [$W$]
  Tiempo esperado que está un cliente en el sistema: $W = E[w]$.
\item [$N_s$]
  Variable aleatoria que describe el número de clientes siendo servidos con el sistema en equilibrio: $N_s = \lim_{t \rightarrow \infty} N_s[t]$.
\item [$L_s$]
  Número esperado de clientes siendo servidos con el sistema en equilibrio: $L_s = E[N_s]$.
\item [$N_q$]
  Variable aleatoria que describe el número de clientes en la cola con el sistema en equilibrio: $N_q = \lim_{t \rightarrow \infty} N_q[t]$.
\item [$L_q$]
  Número esperado de clientes en la cola con el sistema en equilibro: $L_q = E[N_q]$.
\item [$N \lbrack t \rbrack$]
  Variable aleatoria que describe el número de clientes en el sistema en el instante $t$: $N[t] = N_q[t]+N_s[t]$.
\item [$N$]
  Variable aleatoria que describe el número de clientes en el sistema con el sistema en equilibrio: $N = N_q+N_s$.
\item [$L$]
  Número esperado de clientes en el sistema en equilibrio: $L = E[N]$.
\item [$p_n \lbrack t \rbrack$]
  Probabilidad de que haya $n$ clientes en el sistema en el instante $t$: es la función masa de probabilidad de $N[t]$.
\item [$p_n$]
  Probabilidad de que haya $n$ clientes en el sistema con el sistema en equilibrio: $p_n = \lim_{t \rightarrow \infty} p_n[t]$ es la función masa de probabilidad de $N$.
\end{itemize}

\subsection{Procesos de Poisson}

\subsubsection{Notación O pequeña}
  \begin{mydefn} 
  Una función $f$ se dice $o(h)$ (formalmente $o\in o(h)$) y lo notamos $f=o(h)$ si se verifica:
  
  \[\lim_{h\rightarrow 0} \frac{f(h)}{h} = 0\]
  \end{mydefn}

  Es decir, una función $f(h)$ es $o(h)$ si al compararla con $h$ suficientemente pequeño, podemos despreciar su
  valor.

  \begin{fact}
  Dados $c_1, \ldots c_n \in \mathbb{R}$, $f_1, \ldots f_n \in o(h)$, entonces $\sum_{i=1} c_i f_i = o(h)$
  \end{fact}

  \begin{proof}
  \[\lim_{h\rightarrow 0} \frac{\sum_{i=1} c_i f_i}{h} = \sum_{i=1}^n{c_i \lim_{h\rightarrow 0} \frac{f_i}{h}} = 0\]
  \end{proof}

\subsubsection{Proceso de Poisson}

  \begin{mydefn} \textbf{Proceso de conteo}\\
  $\{N(t)\}_{t\ge 0}$, proceso estocástico discreto, es proceso de conteo si se verifica:
  \begin{enumerate}
    \item No negatividad: $N(t) \in \mathbb{N}\cup\{0\}, \quad \forall t\ge 0$. Además: $N(0)=0$
    \item Monotonía: $N(s) \le N(t), \quad s \le t$
  \end{enumerate}

  $N(t)$ indica el número de eventos que han ocurrido en el intervalo $[0,t]$. Por tanto $N(t)- N(s)$, con $t\ge s$
  indica el número de eventos que han ocurrido en $]s,t]$.
  \end{mydefn}


  \begin{mydefn} \textbf{Proceso de Poisson}\\
  Un proceso de conteo $\{N(t)\}_{t\ge 0}$ verifica que es de Poisson de parámetro $\lambda > 0$ si se verifica:
  
  \begin{enumerate}
    \item El proceso tiene incrementos independientes: dados $0 \le t_1 < \ldots < t_n$, se verifica que
    las variables $N(t_0), N(t_1) - N(t_0), \ldots N(t_n)- N(t_{n-1})$ son independientes. Esto es, el número de eventos
    que se producen en intervalos disjuntos es independiente.
    \item El proceso tiene incrementos estacionarios: $N(t+h), N(t)$ tienen la misma distribución para cualesquiera
    $t\ge 0, h\ge 0$
    \item $P[N(h) = 1] = \lambda h + o(h)$, es decir, la probabilidad de que ocurra un evento en un intervalo de
    tiempo de longitud $h$ es casi proporcional a $h$, salvo por un término despreciable en comparación con dicho $h$, para
    $h$ suficientemente pequeño.
    \item $P[N(h) \ge 2] = o(h)$
  \end{enumerate}

  Se deduce que: 
  \[P[N(h) = 0] = 1 - P[N(h)=1] - P[N(h) \ge 2] = 1 -\lambda h - o(h)\]
  \end{mydefn}


La mayoría de modelos de colas asumen una distribución exponencial para tiempos entre llegadas y tiempos 
de servicio, o equivalentemente una distribución de Poisson para frecuencias de llegada y servicio.

\begin{theorem}
 Sea $\{N(t)\}_{t\ge 0}$ un proceso de Poisson de parámetro $\lambda > 0$. Entonces la variable aleatoria $Y$ que
 describe el número de eventos en cualquier intervalo de longitud $t > 0$ tiene una distribución de Poisson de parámetro
 $\lambda t$
 
 \[P[Y = k] = P[N(t) = n] = e^{-\lambda t} \frac{(\lambda t)^k}{k!}, \quad k\ge 0\]
 
 %% Prueba: falta por hacer.
\end{theorem}


\begin{theorem}
 Sea $\{N(t)\}_{t\ge 0}$ proceso de conteo. Sean $0 < t_n$ con $t_{n} < t_{n+1}, \quad forall n\in 
 \mathbb{N}$ tiempos de eventos con $\tau_1= t_1, \tau_{n+1} = t_{n+1} - t_{n}, \quad \forall n\in
 \mathbb{N}$ tiempos entre llegadas. Entonces equivalen:
 
 \begin{itemize}
  \item $\{N(t)\}_{t\ge 0}$ es proceso de Poisson
  \item Los tiempos entre llegadas $\{\tau_n\}$ son variables exponenciales i.i.d. de media $\frac{1}{\lambda}$
 \end{itemize}

\end{theorem}

%% Prueba: falta por hacer.

\begin{theorem}
 Sea $\{N(t)\}_{t\ge 0}$ proceso de Poisson donde un evento ha tenido lugar en $[0,t]$. Entonces siendo $Y$ la variable
 describiendo el número de eventos en cualquier intervalo de longitud $t > 0$, entonces $Y \sim U([0,t])$.
\end{theorem}

%% Prueba: falta por hacer.

\subsubsection{Propiedad de Markov de la distribución exponencial}


%% ¿Qué es exactamente la propiedad de Markov?
\begin{fact}
 Sea $T$ variable aleatoria tal que: $T \sim exp(\lambda)$. Entonces $T$ tiene la propiedad de Markov, esto es:
 
 \[P[T \le t_1 | T \ge t_0] = P[0\le T \le t_1 - t_0] \]
\end{fact}

\begin{proof}
 \begin{align*}
 P[T \le t_1 \mid T\ge t_0] & =  \frac{P([T\le t_1] \cap [T\ge t_0])}{P([T\ge t_0])} = \frac{e^{-\lambda t_0} - e^{-\lambda t_1}}{e^{-\lambda t_0}} = \\
                            & =  1 - e^{-\lambda(t_1 - t_0)} = P[0\le T \le t_1-t_0]
 \end{align*}
\end{proof}

\section{Procesos de nacimiento y muerte}


%% Mas cosas

%% Notación de Kendall
%% \subsection{a}
%% \begin{itemize}
%%   %% Falta
%% \item[$K$]
%%   La capacidad del sistema (mayor número de clientes que puede haber en el sistema)
%% \item[$m$]
%%   El tamaño de la población.
%% \item[$Z$]
%%   La disciplina de la cola.

%% \end{itemize}



%% Ejemplo de cita: \cite{Ciarlet}

\newpage
\begin{thebibliography}{10}
  \expandafter\ifx\csname url\endcsname\relax
  \def\url#1{\texttt{#1}}\fi
  \expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{URL }\fi
  \expandafter\ifx\csname href\endcsname\relax
  \def\href#1#2{#2} \def\path#1{#1}\fi

\bibitem{Ciarlet}
  Ciarlet, P. G. (1982).
  Introduction to numerical linear algebra and optimisation.
  Cambridge University Press

\end{thebibliography}

\end{document}
