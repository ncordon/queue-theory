\documentclass[a4paper,10pt]{scrartcl}

% Inclusión de paquetes
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\usepackage{verbatim}
\usepackage{amsthm}
% Imágenes
\usepackage{graphicx}

% Definiciones
\theoremstyle{definition}
\newtheorem*{mydef}{Definición}
%\newtheorem{mydefn}{Definición}
\newtheorem*{theorem}{Teorema}
\newtheorem*{fact}{Proposición}
\newtheorem*{corollary}{Corolario}
\newtheorem*{eg}{Ejemplo}
\everymath{\displaystyle} % Displaystyle por defecto

% Comandos
\newcommand{\Referencia}[4]{\indent #1, \textbf{#2}. \textit{#3}, \textit{#4}.\\}
\renewcommand\refname{Referencias}
\renewcommand\contentsname{Contenidos}
\numberwithin{equation}{section}
\setlength{\parindent}{0cm} % Sin sangrías
\setlength{\parskip}{0.1cm}

% Sintaxis: \Algoritmo{Elementos de entrada}{Elementos de proceso}{Elementos de salida}
\newcommand{\Algoritmo}[3]{\textbf{Entrada} \begin{itemize} #1 \end{itemize} \textbf{Proceso} \begin{enumerate} #2 \end{enumerate} \textbf{Salida} \begin{itemize} #3 \end{itemize}}

\title{Teoría de Colas}
\author{
  Marta Andrés\and
  Ignacio Cordón\and
  Bartolomé Ortiz\and
}
\date{}

\begin{document}
\maketitle

\begin{center}
  \includegraphics[width=0.4\textwidth]{./imgs/by-nc-sa.png}
\end{center}

\tableofcontents
\pagebreak

\section{Preliminares}

\subsection{Distribución exponencial}
\subsubsection{Propiedad de Markov de la distribución exponencial}


%% ¿Qué es exactamente la propiedad de Markov?
\begin{fact}
 Sea $T$ variable aleatoria tal que: $T \sim exp(\lambda)$. Entonces $T$ tiene la propiedad de Markov, esto es:
 
 \[P[T \le t_1 | T \ge t_0] = P[0\le T \le t_1 - t_0] \]
\end{fact}

\begin{proof}
 \begin{align*}
 P[T \le t_1 \mid T\ge t_0] & =  \frac{P([T\le t_1] \cap [T\ge t_0])}{P([T\ge t_0])} = \frac{e^{-\lambda t_0} - e^{-\lambda t_1}}{e^{-\lambda t_0}} = \\
                            & =  1 - e^{-\lambda(t_1 - t_0)} = P[0\le T \le t_1-t_0]
 \end{align*}
\end{proof}


\subsection{Procesos de Poisson}

\subsubsection{Notación O pequeña}
  \begin{mydef} 
  Una función $f$ se dice $o(h)$ (formalmente $o\in o(h)$) y lo notamos $f=o(h)$ si se verifica:
  
  \[\lim_{h\rightarrow 0} \frac{f(h)}{h} = 0\]
  \end{mydef}

  Es decir, una función $f(h)$ es $o(h)$ si al compararla con $h$ suficientemente pequeño, podemos despreciar su
  valor.

  \begin{fact}
  Dados $c_1, \ldots c_n \in \mathbb{R}$, $f_1, \ldots f_n \in o(h)$, entonces $\sum_{i=1} c_i f_i = o(h)$
  \end{fact}

  \begin{proof}
  \[\lim_{h\rightarrow 0} \frac{\sum_{i=1} c_i f_i}{h} = \sum_{i=1}^n{c_i \lim_{h\rightarrow 0} \frac{f_i}{h}} = 0\]
  \end{proof}

\subsubsection{Proceso de Poisson}

  \begin{mydef} \textbf{Proceso de conteo}\\
  $\{N_t\}_{t\ge 0}$, proceso estocástico discreto, es proceso de conteo si se verifica:
  \begin{enumerate}
    \item No negatividad: $N_t \in \mathbb{N}\cup\{0\}, \quad \forall t\ge 0$. Además: $N(0)=0$
    \item Monotonía: $N_s \le N_t, \quad s \le t$
  \end{enumerate}

  $N_t$ indica el número de eventos que han ocurrido en el intervalo $[0,t]$. Por tanto $N_t- N_s$, con $t\ge s$
  indica el número de eventos que han ocurrido en $]s,t]$.
  \end{mydef}


  \begin{mydef} \textbf{Proceso de Poisson}\\
  Un proceso de conteo $\{N_t\}_{t\ge 0}$ verifica que es de Poisson de parámetro $\lambda > 0$ si se verifica:
  
  \begin{enumerate}
    \item El proceso tiene incrementos independientes: dados $0 \le t_1 < \ldots < t_n$, se verifica que
    las variables $N_{t_0}, N_{t_1} - N_{t_0}, \ldots N_{t_n}- N_{t_{n-1}}$ son independientes. Esto es, el número de eventos
    que se producen en intervalos disjuntos es independiente.
    \item El proceso tiene incrementos estacionarios: $N_{t+h}, N_t$ tienen la misma distribución para cualesquiera
    $t\ge 0, h\ge 0$
    \item $P[N_h = 1] = \lambda h + o(h)$, es decir, la probabilidad de que ocurra un evento en un intervalo de
    tiempo de longitud $h$ es casi proporcional a $h$, salvo por un término despreciable en comparación con dicho $h$, para
    $h$ suficientemente pequeño.
    \item $P[N(h) \ge 2] = o(h)$
  \end{enumerate}

  Se deduce que: 
  \[P[N_h = 0] = 1 - P[N_h=1] - P[N(h) \ge 2] = 1 -\lambda h - o(h)\]
  \end{mydef}


La mayoría de modelos de colas asumen una distribución exponencial para tiempos entre llegadas y tiempos 
de servicio, o equivalentemente una distribución de Poisson para frecuencias de llegada y servicio.

\begin{theorem}
 Sea $\{N_t\}_{t\ge 0}$ un proceso de Poisson de parámetro $\lambda > 0$. Entonces la variable aleatoria $Y$ que
 describe el número de eventos en cualquier intervalo de longitud $t > 0$ tiene una distribución de Poisson de parámetro
 $\lambda t$
 
 \[P[Y = k] = P[N_t = n] = e^{-\lambda t} \frac{(\lambda t)^k}{k!}, \quad k\ge 0\]
 
 %% Prueba: falta por hacer.
\end{theorem}


\begin{theorem}
 Sea $\{N_t\}_{t\ge 0}$ proceso de conteo. Sean $0 < t_n$ con $t_{n} < t_{n+1}, \quad forall n\in 
 \mathbb{N}$ tiempos de eventos con $\tau_1= t_1, \tau_{n+1} = t_{n+1} - t_{n}, \quad \forall n\in
 \mathbb{N}$ tiempos entre llegadas. Entonces equivalen:
 
 \begin{itemize}
  \item $\{N_t\}_{t\ge 0}$ es proceso de Poisson
  \item Los tiempos entre llegadas $\{\tau_n\}$ son variables exponenciales i.i.d. de media $\frac{1}{\lambda}$
 \end{itemize}

\end{theorem}

%% Prueba: falta por hacer.

\begin{theorem}
 Sea $\{N_t\}_{t\ge 0}$ proceso de Poisson donde un evento ha tenido lugar en $[0,t]$. Entonces siendo $Y$ la variable
 describiendo el número de eventos en cualquier intervalo de longitud $t > 0$, entonces $Y \sim U([0,t])$.
\end{theorem}

%% Prueba: falta por hacer.

\subsection{Procesos de nacimiento y muerte}

El parámetro $\lambda$ de un proceso de Poisson $\{N_t\}_{t\ge 0}$ puede ser visto como una tasa de nacimiento, ya que la probabilidad
de que ocurra un evento en un intervalo de longitud $h$ es $P[N(h)-N(0)=1] = \lambda h e^{-\lambda h} = \lambda h + o(h)$.
Cuando suponemos que el parámetro no es constante, sino que depende de $n$ (cantidad de eventos que se han producido hasta el momento), esto
es $\lambda_n$, entonces la cantidad de nacimientos (eventos producidos) en un intervalo de longitud $h$ es $\lambda_n h + o(h)$. Si además
establecemos que se pueden producir muertes con una tasa $\mu_n$, donde la probabilidad de que se produzca una muerte en un intervalo de longitud
$h$ es $\mu_n h + o(h)$ tenemos un proceso de nacimiento y muerte.

\begin{mydef}
 Sea una cadena de Markov $\{N_t\}_{t\ge 0}$ con espacio de estados $\mathbb{N}\cup \{0\}$, donde el espacio de estados representa el número de individuos
 de un sistema (población). Entonces $\{N_t\}_{t\ge 0}$ se dice proceso de nacimiento y muerte si existen tasas no negativas de nacimiento y muerte,
 $\{\lambda_n\}_{\mathbb{N}\cup \{0\}}$ y $\{\mu_n\}_{\mathbb{N}\cup \{0\}}$ y se verifica:
 
 \begin{enumerate}
  \item La población puede aumentar o decrecer únicamente de uno en uno.
  \item Si el sistema está en estado $n\ge 0$ entonces el tiempo hasta que el sistema está en estado $n+1 \ge 0$ es una variable aleatoria exponencial
  de paŕámetro $\lambda_n$
  \item Si el sistema está en estado $n\ge 1$ entonces el tiempo hasta que el sistema está en estado $n-1 \ge 0$ es una variable aleatoria exponencial
  de paŕámetro $\mu_n$
 \end{enumerate}
\end{mydef}

Llamando $P_n(t) = P[N_t = n]$ se verifica:

% Falta arreglar y transcribir la demostración de esto, que está mal en el libro
\[P_n(t+h) = [1-\lambda_n h -\mu_n h] P_n(t) + \lambda_{n-1} h P_{n-1}(t) + \mu_{n+1} h P_{n+1}(t) + o(h)\]

que diviendo por $h$ en ambos términos y operando, da lugar a:

\[\frac{P_n(t+h) - P_n(t)}{h} = -(\lambda_n + \mu_n) P_n(t) + \lambda_{n-1} P_{n-1}(t) + \mu_{n+1}P_{n+1}(t) + \frac{o(h)}{h}\]

Tomando límite en $h\rightarrow 0$ llegamos a:

\begin{equation}
\frac{\partial P_n(t)}{\partial t} = -(\lambda_n + \mu_n) P_n(t) + \lambda_{n-1}P_{n-1}(t) + \mu_{n+1}P_{n+1}(t)
\label{eq:recp_n(t)}
\end{equation}

En el caso particuar $n=0$, tenemos $\mu_o = 0$ y $P_{-1}(t) = 0$. Por tanto:

\begin{equation}
 \frac{\partial P_0(t)}{\partial t} = -\lambda_0 P_0(t) \mu_{1}P_{1}(t)
 \label{eq:recp_0(t)}
\end{equation}


Supongamos en lo que sigue que existe la distribución límite, esto es 
$\lim_{t\rightarrow \infty}\{P_n(t)\} = p_n$ y haciendo $t\rightarrow \infty$ en \eqref{eq:recp_n(t)},
y en \eqref{eq:recp_0(t)} llegamos a que:

\begin{align*}
0 &= \lambda_{n-1} p_{n-1} + \mu_{n+1} p_{n+1} - (\lambda_n + \mu_n) p_n, \quad n\ge 1\\
0 &= \mu_1 p_1 -\lambda_0 p_0, \quad n=0
\end{align*}

Veamos por inducción que: $p_n = p_0 \prod_{i=1}^n \frac{\lambda_{i-1}}{\mu_i}, \quad n\ge 1$.

\begin{proof}
 Los casos $n=0, n=1$ cumplen trivialmente la recurrencia. Para $n>0$, aplicando hipótesis de inducción a $p_{n-1}, p_{n}$:
 
 \begin{align*}
 p_{n+1} &= \frac{\lambda_n + \mu_n}{\mu_{n+1}} p_n - \frac{\lambda_{n-1}}{\mu_{n+1}}p_{n-1} = \\
         &= \frac{\lambda_n + \mu_n}{\mu_{n+1}} p_0 \prod_{i=1}^n \frac{\lambda_{i-1}}{\mu_i} - 
            \frac{\lambda_{n-1}}{\mu_{n+1}} p_0 \prod_{i=1}^{n-1} \frac{\lambda_{i-1}}{\mu_i} = \\
         &= \frac{\lambda_n}{\mu_{n+1}} p_0 \prod_{i=1}^n \frac{\lambda_{i-1}}{\mu_i} + 
            \frac{\mu_n \lambda_{n-1}}{\mu_{n+1}\mu_n} p_0 \prod_{i=1}^{n-1} \frac{\lambda_{i-1}}{\mu_i} - 
            \frac{\lambda_{n-1}}{\mu_{n+1}} p_0 \prod_{i=1}^{n-1} \frac{\lambda_{i-1}}{\mu_i} = \\
         &= \frac{\lambda_n}{\mu_{n+1}} p_0 \prod_{i=1}^n \frac{\lambda_{i-1}}{\mu_i} = p_0 \prod_{i=1}^{n+1} \frac{\lambda_{i-1}}{\mu_i}
 \end{align*}
\end{proof}

Las probabilidades deben sumar $1$, esto es $1 = \sum_{n=0}^{\infty} p_n = p_0 \underbrace{\left(1 + \sum_{n=1}^{\infty} \prod_{i=1}^n \frac{\lambda_{i-1}}{\mu_i} \right)}_{S}$

Que la serie $S$ sea convergente es condición necesaria para que exista la distribución límite. 
De hecho, también es condición suficiente. Si dicha distribución existe se tendría: 

\begin{equation}
 p_0 = S^{-1} 
 \label{eq:relp0}
\end{equation}


\section{El modelo de un \textit{``sistema de encolado''}}
Un sistema de encolado es una cosa tal que así [dibujo aquí], en la que se consideran las siguientes variables aleatorias:

\begin{itemize}
\item [$c$]
  Número (fijo) de servidores o canales en el sistema, $c\in \mathbb{N} \cup \{+\infty\}$
\item [$\tau$]
  Variable aleatoria que describe el tiempo entre llegadas (de clientes).
\item [$S$]
  Variable aleatoria que describe el tiempo de servicio.
  %% o [que tarda un cliente en ser servido] ?
\item [$Q$]
  Variable aleatoria que describe el tiempo que espera un cliente en la cola.
  %% [incóginta?]
\item [$N_{S,t}$]
  Variable aleatoria que describe el número de clientes que están siendo servidos en el instante $t$.
  %% [dependerá de $\tau$, $s$, $c$? y de más cosas?]
\item [$N_{Q,t}$]
  Variable aleatoria que describe el número de clientes en la cola (esperando a ser servidos) en el instante $t$.
  %% [depende también?]
\end{itemize}

%% Resaltar que $q$ no se conoce y es la que interesa conocer en general? $N_q[t]$ y $N_s[t]$ dependen también de otras cosas.

De ellos se derivan las siguientes variables, también relevantes:
\begin{itemize}
\item [$\lambda$]
  Frecuencia o tasa media de llegadas de clientes al sistema: $\lambda = 1/E[\tau]$.
\item [$\mu$]
  Frecuencia o tasa media de servicio de los servidores del sistema: $\mu = 1/E[S]$.
\item [$\rho$]
  Aprovechamiento de los servidores, esto es, la proporción de tiempo que los servidores están trabajando: $\rho = \frac{\lambda}{c\mu}$.
  %% $= \frac{E[N_s]}{c} = \frac{L_s}{c}$ por qué?
\item [$W_S$]
  Tiempo medio que está siendo servido un cliente: $W_S  = E[S]$.
\item [$W_Q$]
  Tiempo medio que está un cliente en la cola: $W_Q = E[Q]$.
\item [$w$]
  Variable aleatoria que describe el tiempo total que un cliente está en el sistema de encolado: $W = Q+S$.
\item [$W$]
  Tiempo medio que está un cliente en el sistema: $W = E[W]$.
\item [$N_S$]
  Variable aleatoria que describe el número de clientes siendo servidos con el sistema en equilibrio: $N_S = \lim_{t \rightarrow \infty} N_s[t]$.
\item [$L_S$]
  Número medio de clientes siendo servidos con el sistema en equilibrio: \\ $L_S = E[N_S]$.
\item [$N_Q$]
  Variable aleatoria que describe el número de clientes en la cola con el sistema en equilibrio: $N_Q = \lim_{t \rightarrow \infty} N_{Q,t}$.
\item [$L_Q$]
  Número medio de clientes en la cola con el sistema en equilibro: $L_Q = E[N_Q]$.
\item [$N_t$]
  Variable aleatoria que describe el número de clientes en el sistema en el instante $t$: $N_t = N_{Q,t} + N_{S,t}$.
\item [$N$]
  Variable aleatoria que describe el número de clientes en el sistema con el sistema en equilibrio (en caso de tener sentido) $N = N_Q + N_S$.
\item [$L$]
  Número medio de clientes en el sistema en equilibrio (en caso de tener sentido): $L = E[N]$.
\item [$P_n(t)$]
  Probabilidad de que haya $n$ clientes en el sistema en el instante $t$: es la función masa de probabilidad de $N_t$.
\item [$p_n$]
  Probabilidad de que haya $n$ clientes en el sistema con el sistema en equilibrio: $p_n = \lim_{t \rightarrow \infty} P_n(t)$ es la función masa de probabilidad de $N$.
\end{itemize}

\subsection{Características de un proceso de colas}
\subsubsection{Modelo de llegadas}
La capacidad de un sistema de colas para poder proporcionar servicio a los clientes no depende solo de la tasa media
de llegadas de un sistema de colas, sino también del modo en que las peticiones llegan. De esta forma, podemos
tener que las peticiones llegan de uno en uno, o en paquetes de peticiones.

Dado $0=t_0 < t_1 < t_2 < t_n < \ldots$, y $\tau_n = t_n - t_{n-1}, \tau_0$ tiempos entre llegadas, asumimos por hipótesis
que las $\tau_n$ son variables aleatorias independientes.

\begin{mydef}
LLamamos modelo de llegadas a la distribución de los $\{t_n\}$
\end{mydef}
 
 La distribución de los tiempos de llegada $\{t_n\}$ está determinada por la distribución de los tiempos entre
 llegadas $\{\tau_n\}$. 
 
\begin{mydef}
El modelo de llegadas se dice:
 
 \begin{enumerate}
   \item Estacionario, si las $\{\tau_n\}$ están idénticamente distribuidas, y notamos $\{\tau\}$ a la variable
   aleatoria que modela el tiempo entre llegadas.
   \item Transitorio, en caso opuesto.
 \end{enumerate}
\end{mydef}

 
\begin{mydef}
 Para un modelo de llegadas estacionario, sea $A(t)$ función de distribución de los $\tau_n$. 
 El modelo de llegadas se dice:

  \begin{enumerate}
  \item Aleatorio o de Poisson: si $A(t) = 1 - e^{-\lambda t}$
  \item Determinístico: si $A(t) = \left\{\begin{array}{ll}
					0 & t<s \\
					1 & t\ge s
					\end{array}\right.$ con $s$ fijo.
  
  \end{enumerate}
\end{mydef}


\subsubsection{Modelo de servicio}

Se pueden efectuar unas definiciones análogas para modelo determinístico, aleatorio y régimen estacionario y transitorio
de servicio a las que se han hecho con el modelo de llegadas.

\begin{eg} \textbf{Caso particular, modelo de Poisson de servicio}

Supongamos que el sistema de encolado tiene $k$ servidores o canales para atender peticiones, y el tiempo que 
tarda cada uno en atender una petición $T_i, i=1,\ldots k$ sigue una distribución exponencial de parámetro $\bar{\mu}$.
Entonces el tiempo hasta terminar de atender una petición es $T = min\{T_1, \ldots T_n\}$. Entonces $T$ sigue
una distribución exponencial de parámetro $\mu = n \bar{\mu}$

La función de distribución de $W_S$ por tanto sería $F(t) = P[S\le t] = 1 - e^{-\mu t}$
\end{eg}

\subsubsection{Capacidad del sistema}
Se llama capacidad al tamaño máximo de la cola de peticiones, esto es $M = \max_t \{N_{Q,t}\}$. Por tanto no puede
tenerse que en ningún tiempo $N_{Q,t}$ tome un valor mayor que $M$, y si llegara una petición cuando la cola tiene
tamaño $M$, se rechazaría dicha petición.

\subsubsection{Comportamiento de los clientes}
Podemos considerar que los clientes que llegan a la cola pueden efectuar:

\begin{itemize}
  \item Oposición: una petición se retira en la llegada (por ejemplo en casos en los que la cola sea muy larga
  y el cliente se abstenga de entrar).
  \item Retirada: la petición entra a la cola, pero tras un tiempo de espera, la deja.
  \item Recolocación: si hay varias colas paralelas, los clientes se pueden cambiar de una cola a otra.
  \item Priorización: algunos clientes pueden tener mayor prioridad que otros al ser servidos.
\end{itemize}

%% Notación de Kendall
%% \subsection{a}
%% \begin{itemize}
%%   %% Falta
%% \item[$K$]
%%   La capacidad del sistema (mayor número de clientes que puede haber en el sistema)
%% \item[$m$]
%%   El tamaño de la población.
%% \item[$Z$]
%%   La disciplina de la cola.

%% \end{itemize}



%% Ejemplo de cita: \cite{Ciarlet}

\newpage
\begin{thebibliography}{10}
  \expandafter\ifx\csname url\endcsname\relax
  \def\url#1{\texttt{#1}}\fi
  \expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{URL }\fi
  \expandafter\ifx\csname href\endcsname\relax
  \def\href#1#2{#2} \def\path#1{#1}\fi

\bibitem{Allen}
  Arnold O.Allen (1990)\\
  Probability, Statistics and Queueing Theory with Computer Science Applications\\
  Academic Press

\bibitem{Gross}
  Donald Gross, John F.Shortle, James M.Thompson, Carl M.Harris (2008)\\
  Fundamentals of Queueing Theory\\
  Wiley
  
\bibitem{Gunavathi}
  P.Kandasamy, K.Thilagavathi, K.Gunavathi\\
  Probability and Queueing Theory (2010)\\
  S. Chand \& Company
\end{thebibliography}

\end{document}
